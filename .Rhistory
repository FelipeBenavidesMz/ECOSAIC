knitr::opts_chunk$set(echo = TRUE)
# CarGar los datos asociados a las características latentes
datos = read.csv("F:/ECOSAIC/data/outputs/LE_DUAL_OPTIMIZED_20260224_170020.csv", h=T)
# Seleccionar las columnas por nombre
features <- datos[, c('LE1_FisicoBio_OPTIMIZED','LE2_Hidro_OPTIMIZED')]
# cargar los datos de ocurrencias
species_occurrences <- read.csv("F:/ECOSAIC/data/outputs/species_ocurrences.csv", h= T, sep=';')
# CarGar los datos asociados a las características latentes
datos = read.csv("F:/ECOSAIC/data/outputs/LE_DUAL_OPTIMIZED_20260224_170020.csv", h=T)
# Seleccionar las columnas por nombre
features <- datos[, c('LE1_FisicoBio_OPTIMIZED','LE2_Hidro_OPTIMIZED')]
# cargar los datos de ocurrencias
species_occurrences <- read.csv("F:/ECOSAIC/data/species_ocurrences.csv", h= T, sep=';')
View(species_occurrences)
# Cargar el archivo que contiene las características latentes y las variables ambientales
datos = read.csv("F:/ECOSAIC/data/outputs/LE_DUAL_OPTIMIZED_20260224_170020.csv", h=T)
# Seleccionar las columnas asociadas a las características latentes
features <- datos[, c('LE1_FisicoBio_OPTIMIZED','LE2_Hidro_OPTIMIZED')]
features_scaled <- scale(features)
head(features)
head(features_scaled)
grid_sizes <- list(c(4,4), c(5, 5), c(7, 7), c(10, 10), c(20, 20), c(1, 1))
rlen_values <- c(50, 100, 200)
alpha_values <- list(c(1, 0.5), c(1, 0.1), c(1,0.01), c(0.5,1), c(0.5,0.5), c(1,0.1))
radius_values <- list(c(10, 5), c(5, 1))
results <- data.frame(
xdim = integer(),
ydim = integer(),
rlen = integer(),
alpha_start = double(),
alpha_end = double(),
radius_start = double(),
radius_end = double(),
quantization_error = double(),
topographic_error = double()
)
for (grid_size in grid_sizes) {
som_grid <- somgrid(grid_size[1], grid_size[2], "rectangular")
for (rlen in rlen_values) {
for (alpha in alpha_values) {
for (radius in radius_values) {
# Train the SOM with the current combination of parameters
set.seed(123) # For reproducibility
som_model <- som(features_scaled, grid = som_grid, rlen = rlen, alpha = alpha, radius = radius)
# Calculate errors
quantization_error <- mean(som_model$distances)
topographic_error <- mean(som_model$changes)
# Store the results
results <- rbind(results, data.frame(
xdim = grid_size[1],
ydim = grid_size[2],
rlen = rlen,
alpha_start = alpha[1],
alpha_end = alpha[2],
radius_start = radius[1],
radius_end = radius[2],
quantization_error = quantization_error,
topographic_error = topographic_error
))
}
}
}
}
library(kohonen)
library(dplyr)
library(raster)
library(ggplot2)
library(sf)
library(geodata)
library(mapview)
library(readxl)
for (grid_size in grid_sizes) {
som_grid <- somgrid(grid_size[1], grid_size[2], "rectangular")
for (rlen in rlen_values) {
for (alpha in alpha_values) {
for (radius in radius_values) {
# Train the SOM with the current combination of parameters
set.seed(123) # For reproducibility
som_model <- som(features_scaled, grid = som_grid, rlen = rlen, alpha = alpha, radius = radius)
# Calculate errors
quantization_error <- mean(som_model$distances)
topographic_error <- mean(som_model$changes)
# Store the results
results <- rbind(results, data.frame(
xdim = grid_size[1],
ydim = grid_size[2],
rlen = rlen,
alpha_start = alpha[1],
alpha_end = alpha[2],
radius_start = radius[1],
radius_end = radius[2],
quantization_error = quantization_error,
topographic_error = topographic_error
))
}
}
}
}
print(results)
ordered_results_topographic = results[order(results$topographic_error),]
ordered_results2_quantization = results[order(results$quantization_error),]
#
ordered_results_final = ordered_results_topographic[ordered_results_topographic$xdim == 4,]
ordered_results_final[ , c(8,9)]   [which.min(rowSums(ordered_results_final[ , c(8,9)])), ]
set.seed(123)
grid_size <- c(4,4)
som_grid <- somgrid(grid_size[1], grid_size[2], "rectangular")
som_opt <- som(features_scaled, grid=som_grid, rlen=100, alpha=c(1, 0.01), radius=c(5,1))
table(som_opt$unit.classif)
raster_som <- rasterFromXYZ(data.frame(datos$longitude, datos$latitude, som_opt$unit.classif))
crs(raster_som) <- CRS("EPSG:3115")
wgs84_crs <- CRS("+proj=longlat +datum=WGS84 +no_defs")
raster_som <- projectRaster(raster_som, crs = wgs84_crs, method = 'ngb')
plot(raster_som, col = rainbow(25))
writeRaster(raster_som, "F:/ECOSAIC/data/ECOSAIC_SOM_BenthicHabitats_ColombianPacific_LE1LE2_4x4_WGS84.tif", overwrite =T)
coordenadas = as.data.frame(coordinates(raster_som))
coordenadas = coordenadas[!is.na(coordenadas),]
tabla_final = data.frame(features_scaled, som_opt$unit.classif)
# Método 1: Usando el paquete 'dplyr' (recomendado)
# Si aún no lo tienes, instálalo: install.packages("dplyr")
library(dplyr)
# Renombrar las columnas de tabla_final antes de la unión
tabla_final_renombrado <- tabla_final %>%
rename(
LE1_FisicoBio_norm = LE1_FisicoBio_OPTIMIZED,
LE2_Hidro_norm = LE2_Hidro_OPTIMIZED,
)
# Unir los dataframes por columna
# La nueva variable 'datos_unidos' contendrá todas las columnas de ambos dataframes
LE_COORDS_VARIABLES_LE_NORM_SOM <- bind_cols(tabla_final_renombrado, datos)
# Visualizar las primeras filas para confirmar que los nombres de las columnas se cambiaron
head(LE_COORDS_VARIABLES_LE_NORM_SOM)
# Define la ruta completa donde quieres guardar el archivo CSV
output_path <- "F:/ECOSAIC/data/outputs/ECOSAIC_LatentFeatures_EnvVariables_SOMclass_ColombianPacific.csv"
# Guarda el dataframe LE_COORDS_VARIABLES_LE_NORM_SOM en la ruta especificada.
# 'row.names = FALSE' evita que se escriba la columna de los números de fila como una columna en el CSV.
# 'overwrite = TRUE' (o simplemente no especificarlo, ya que es el comportamiento por defecto en R para write.csv)
# sobrescribirá el archivo si ya existe.
write.csv(LE_COORDS_VARIABLES_LE_NORM_SOM, output_path, row.names = FALSE)
cat(paste("✅ ¡Éxito! El dataframe ha sido guardado en:", output_path, "\n"))
